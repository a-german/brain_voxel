{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "export_path = '/Your export path'\n",
    "f = h5py.File('TRAIN38.mat','r')\n",
    "arrays = {}\n",
    "for k, v in f.items():\n",
    "  arrays[k] = np.array(v)\n",
    "f.close()\n",
    "train_data = arrays['data'].transpose()\n",
    "train_region = arrays['region'].transpose()\n",
    "prob_idx = arrays['prob_idx'].transpose()\n",
    "del arrays, f\n",
    "curr_set = np.where(prob_idx != 38)[0]\n",
    "set_data = train_data[curr_set,:]\n",
    "set_region = train_region[curr_set,:]\n",
    "print(set_data.shape)\n",
    "curr_val = np.where(prob_idx == 38)[0]\n",
    "val_data = train_data[curr_val,:]\n",
    "val_label = train_region[curr_val,:]\n",
    "print(val_data.shape)\n",
    "del curr_set, curr_val, train_data, train_region\n",
    "X_train1, X_train2, y_train1, y_train2 = train_test_split(set_data,set_region,test_size = 0.01, random_state = 42)\n",
    "del set_data, set_region\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train1)\n",
    "X_train1 = scaler.transform(X_train1)\n",
    "val_data = scaler.transform(val_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train model\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import backend as K\n",
    "from keras import activations\n",
    "# Model configuration\n",
    "batch_size = 128\n",
    "no_epochs = 25\n",
    "no_classes = 102\n",
    "\n",
    "def create_reg_model():\n",
    "  input_shape = [341]\n",
    "  model = Sequential()\n",
    "  model.add(Dense(4096, activation='relu', input_shape=input_shape, kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(4096, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(4096, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(4096, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(no_classes, activation='softmax', name='visualized_layer'))\n",
    "  return model\n",
    "model = create_reg_model()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train1,y_train1,\n",
    "          epochs=no_epochs,\n",
    "          batch_size = batch_size,\n",
    "          validation_data=(val_data,val_label))\n",
    "model.save(export_path + 'dense_4x4096_model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#apply model\n",
    "filepath = 'DEMO38.mat'\n",
    "arrays = {}\n",
    "f = h5py.File(filepath,'r')\n",
    "for k, v in f.items():\n",
    "  arrays[k] = np.array(v)\n",
    "f.close()\n",
    "multidim_data = arrays['multidim_data'].transpose()\n",
    "del arrays, f\n",
    "multidim_data = scaler.transform(multidim_data)\n",
    "predicted_ann = model.predict(multidim_data)\n",
    "predictpath = 'Your predictpath'\n",
    "scipy.io.savemat(predictpath +'dense_4x4096_model_prediction.mat', mdict={'predicted_ann':predicted_ann})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate and visualize saliency\n",
    "!pip install https://github.com/raghakot/keras-vis/archive/master.zip\n",
    "\n",
    "from vis.visualization import visualize_saliency\n",
    "from vis.utils import utils\n",
    "import matplotlib.pyplot as plt\n",
    "# Numbers to visualize\n",
    "indices_to_visualize = [ 10000, 20000, 30000, 40000, 50000, 60000 ] #or range(0,173383)\n",
    "layer_index = utils.find_layer_idx(model, 'visualized_layer')\n",
    "# Visualize\n",
    "for index_to_visualize in indices_to_visualize:\n",
    "  # Get input\n",
    "  input_spectrum = val_data[index_to_visualize,:,:]\n",
    "  input_class = np.argmax(val_label[index_to_visualize,:])\n",
    "  print(str(input_class))\n",
    "  # Generate visualization\n",
    "  #visualize_saliency_with_losses(input_tensor, losses, seed_input, keepdims=True)\n",
    "  visualization = visualize_saliency(model, layer_index, filter_indices=input_class, seed_input=input_spectrum, keepdims=True)\n",
    "  plt.figure()\n",
    "  plt.title(str(input_class))\n",
    "  plt.plot(visualization,'g')\n",
    "  plt.plot(scaler.inverse_transform(input_spectrum),alpha=0.25)\n",
    "  plt.plot(input_spectrum,'b',alpha=0.3)\n",
    "  plt.axvspan(0, 15, color='gray', alpha=0.3)\n",
    "  plt.axvspan(225, 230, color='gray', alpha=0.2)\n",
    "  plt.show"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}